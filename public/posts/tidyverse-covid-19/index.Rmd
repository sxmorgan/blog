---
title: 'Introduction to the Tidyverse'
subtitle: 'COVID-19 Testing in the US'
author: Morgan Essex
date: '2020-04-27'
slug: tidyverse-covid-19
output:
  blogdown::html_page:
    toc: true
tags:
  - tidyverse
  - tutorials
  - r-stats
  - forslund-lab
---

The [tidyverse](https://www.tidyverse.org/packages/) is a set of actively developed and well-maintained R packages to facilitate the typical data analysis workflow, shown below. Most but not all of the core tidyverse packages (there are now 8) were designed by Hadley Wickham, chief scientist at R Studio since 2013. He's written a book, [_R for Data Science_](https://r4ds.had.co.nz/), which is an incredible resource for all programming levels, and given several talks which are of course available on YouTube if you find yourself becoming a nerd too... [here's a good one](https://www.youtube.com/watch?v=9YTNYT1maa4) from the [VIZBI](https://vizbi.org/) conference at EMBL last year. 

In 2007 he published probably the most well-known component of the tidyverse, `ggplot2`, as an open source implementation of [_The Grammar of Graphics_](https://towardsdatascience.com/a-comprehensive-guide-to-the-grammar-of-graphics-for-effective-visualization-of-multi-dimensional-1f92b4ed4149), a statistical textbook from the 1980s that looked at the fundamentals of data visualization. Grammar is an attribute of language that tells us how elements must be expressed in order to be understood, and where natural languages predominately evolve the grammars that distinguish them functionally, programming languages can be created or tweaked to suit a specific need from the beginning. _The Grammar of Graphics_ is just a rationally-designed graphic language embedded in a programming language (hence **gg**plot). 

What it accomplished for the process of data visualization - the ability to describe and construct an array of visualizations in a layered, structured manner - was extended to other aspects of the data analysis process and refined over years to become the tidyverse in 2016. R users who have ever melted or reshaped a data frame might be curious to know that those packages were also Hadley's work and key predecessors of the `dplyr` and `tidyr` packages in the current core tidyverse.

![](data/data.science.process.png)
<br><br>
I personally really like the graphic above because it unites the computational data sciences regardless of motivating discipline or question and encapsulates my entire job as a researcher: it starts with data and ends with me communicating something I've learned from the nonlinear process of exploring that data. This process was already strenuous during my master's thesis, so I knew that I would need to get a lot better at organizing my efforts and gain a lot of technical proficiency in order to complete my PhD. The tidyverse attracted me because it offered consistency and complete workflow coverage, which felt like were the best ways to attain the fluency I needed to do my job effectively. 

At most I hope I can inspire someone else to interact with their data science questions differently too - with more curiosity and flow, and less frustration and disorganization - and at the very least I hope people will consider using chaining syntax for more readable code.

### Tidy Philosophy

### Import

We're going to be using data from the COVID Tracking Project in the US. The API is easily accessible, and a woman already created a wrapper package for R to make accessing historical and current statistics incredibly simple.

![](data/covidtracking.png)

Calling `library(tidyverse)` will load all the functions we'll need today, except we must also import `magrittr`, which provides us with the pipe (`%>%`) operator and some 'aliases' useful when using chaining syntax.

```{r knitr, include = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

```{r libraries}
library(tidyverse)  # data science toolkit
library(magrittr)   # corresponding operators
library(covid19us)  # scrapes https://covidtracking.com/ API
library(ggsci)      # custom color palettes
library(ggpubr)     # publication-ready plots
```

Then, let's load the complete longitudinal dataset and select the variables that will be relevant for our analysis.

```{r load.data.1}
states.data <- get_states_daily() %>%
    select(c('state','date','positive','negative','death','total_test_results'))

states.data
```

Additionally, we're going to pull a csv file from https://worldpopulationreview.com/ that contains state-abbreviation pairs (e.g. CA, California) that we'll use later to 'beautify' our plots.

```{r load.data.2}
states.abbrev <- read_csv('https://worldpopulationreview.com/static/states/abbr-name-list.csv')

states.abbrev
```

Lastly, from that same website I have downloaded the (projected) 2020 census estimates, which we'll read in and use to standardize our data to tests per 100,000 residents.

```{r load.data.3}
states.population <- 'data/covid.us.state.population.csv' %>%
    read_csv() %>%
    select(c('rank','State','Pop'))

states.population
```


### Munge
To munge is to manipulate raw data. We'll start by combining the three different datasets we have loaded to look at testing rates among the most populated states.

```{r munge.1}
testing.data <- states.data %>%
    left_join(states.abbrev, by = c('state' = 'abbreviation')) %>%
    left_join(states.population, by = c('name' = 'State'))

# peeking at newly joined variables
testing.data %>%
    select(c('state','date','name','rank','Pop'))
```

Then we'll use the lubridate package within the tidyverse to quickly split the dates into month and day components so we can look at data from the 9th of March.

```{r munge.2}
testing.data %<>%
    mutate(month = lubridate::month(date)) %>%
    mutate(day = lubridate::day(date)) %>%
    filter(month >= 3) %>%
    filter(day >= 9)

testing.data %>%
    select(c('state','date','total_test_results','month','day'))
```


### Plot
