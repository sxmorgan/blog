---
title: 'Introduction to the Tidyverse'
subtitle: 'COVID-19 Testing in the US'
author: Morgan Essex
date: '2020-04-27'
slug: tidyverse-covid-19
categories:
  - R
tags:
  - tidyverse
description: '...'
---

We're going to be using data from the COVID Tracking Project in the US. The API is easily accessible, and a woman already created a wrapper package for R to make accessing historical and current statistics incredibly simple. 

![](../data/covid-tidyverse/covidtracking.png)

<br><br>
First, let's load the packages we'll use for this analysis. Calling `library(tidyverse)` will load all the functions we'll need today, except we must also import `magrittr`, which provides us with the pipe (`%>%`) operator for chaining syntax.

```{r libraries, echo = FALSE}
library(tidyverse)  # data science toolkit
library(magrittr)   # corresponding operators
library(covid19us)  # scrapes https://covidtracking.com/ API
library(ggsci)      # custom color palettes
library(ggpubr)     # publication-ready plots
library(knitr)      # create docs of text + code
```

<br><br>
Then, let's load the complete longitudinal dataset and select the variables that will be relevant for our analysis. Additionally, we're going to pull a csv file from https://worldpopulationreview.com/ that contains state-abbreviation pairs (e.g. CA, California) that we'll use later to 'beautify' our plots. Lastly, from that same website I have downloaded the (projected) 2020 census estimates, which we'll read in and use to standardize our data to e.g. tests per 100,000 residents.

```{r load.data}
states.data <- get_states_daily() %>%
    select(c('state','date','positive','negative','death','total_test_results'))

states.data %>%
    dplyr::slice(1:10) %>%
    knitr::kable(results = 'html')

states.abbrev <- read_csv('https://worldpopulationreview.com/static/states/abbr-name-list.csv')

states.population <- '../data/covid-tidyverse/covid.us.state.population.csv' %>%
    read_csv() %>%
    select(c('rank','State','Pop'))
```